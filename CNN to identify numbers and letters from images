{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zemWtDr8gVOf"
      },
      "source": [
        "Training an EMNIST classifier\n",
        "\n",
        "EMNIST is just like MNIST, a bunch of handwritten images, except instead of just digits (0-9) it also has uppercase and lowercase characters.\n",
        "\n",
        "This project creates and trains an EMNIST classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4GQMlmw2hwbn"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Needed imports"
      ],
      "metadata": {
        "id": "9rDkAVVf74Hz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8j3LQ1Qza-vV"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "from torchvision.datasets import EMNIST\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.functional import normalize\n",
        "from torchvision import transforms\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pre-propressing the data"
      ],
      "metadata": {
        "id": "Lz77w28d8U5O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "InCfHKZme7ga",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16ab0a41-ea3b-4610-d19c-1346e22de86b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://biometrics.nist.gov/cs_links/EMNIST/gzip.zip to emnist_data/EMNIST/raw/gzip.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 561753746/561753746 [00:08<00:00, 65347271.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting emnist_data/EMNIST/raw/gzip.zip to emnist_data/EMNIST/raw\n"
          ]
        }
      ],
      "source": [
        "# Must transform the data to tensors and also normalise\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "#applying the transform function to the data sets\n",
        "\n",
        "train_data = EMNIST(root='emnist_data/', split='byclass', download=True, transform=transform)\n",
        "test_data = EMNIST(root='emnist_data/', split='byclass', download=True, train=False, transform=transform)\n",
        "\n",
        "# now using the dataloader function\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=64, shuffle = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using a convolutional neural network"
      ],
      "metadata": {
        "id": "8x64EM6IJLUz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definining the CNN\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        #creating the layers\n",
        "        self.conv1 = nn.Conv2d(1, 100, 3, 1, 1)\n",
        "        self.conv2 = nn.Conv2d(100, 15, 3, 1, 1)\n",
        "        self.fc1 = nn.Linear(15 * 7 * 7, 128)\n",
        "        self.fc2 = nn.Linear(128, 62)\n",
        "\n",
        "    # defining the forward pass\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, (2, 2))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, (2, 2))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "#Creating an instance of the CNN\n",
        "C_net = CNN()\n",
        "\n",
        "# Processing through GPU if possible\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "C_net.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7A8TtXiX6V1",
        "outputId": "c9687f77-ff67-47e3-b39a-eb94efa2ea7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (conv1): Conv2d(1, 100, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv2): Conv2d(100, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (fc1): Linear(in_features=735, out_features=128, bias=True)\n",
              "  (fc2): Linear(in_features=128, out_features=62, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training and testing the neural network on the data\n",
        "num_iter = 10\n",
        "\n",
        "# optimisation function\n",
        "opt = optim.SGD(C_net.parameters(), lr=0.01, momentum=0.5)\n",
        "\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "test_losses = []\n",
        "test_accuracies = []\n",
        "\n",
        "#beginning the training\n",
        "for i in tqdm(range(num_iter)):\n",
        "    C_net.train()  # setc the network to training mode\n",
        "    running_loss = 0.0\n",
        "    total_train = 0\n",
        "    correctly_labelled_train = 0\n",
        "\n",
        "    for x, y in train_loader:\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        yhat = C_net(x)  # forward pass\n",
        "        loss = F.cross_entropy(yhat, y)  # loss\n",
        "\n",
        "        opt.zero_grad()  # optimization\n",
        "        loss.backward()  # back pass\n",
        "        opt.step()  # opt step\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        yhat = torch.argmax(yhat, dim=1)\n",
        "        total_train += y.size(0)\n",
        "        correctly_labelled_train += (yhat == y).sum().item()\n",
        "\n",
        "    iter_loss = running_loss / len(train_loader)\n",
        "    train_losses.append(iter_loss)\n",
        "    train_accuracy = correctly_labelled_train / total_train * 100\n",
        "    train_accuracies.append(train_accuracy)\n",
        "\n",
        "    # Now testing\n",
        "    C_net.eval()  # set the network to evaluation mode\n",
        "    correctly_labelled_test = 0\n",
        "    total_test = 0\n",
        "    test_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for x, y in test_loader:\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "            logits = C_net(x)\n",
        "            loss = F.cross_entropy(logits, y)\n",
        "            test_loss += loss.item()\n",
        "            yhat = torch.argmax(logits, dim=1)\n",
        "            correctly_labelled_test += (yhat == y).sum().item()\n",
        "            total_test += y.size(0)\n",
        "\n",
        "    test_loss /= len(test_loader)\n",
        "    test_losses.append(test_loss)\n",
        "    test_accuracy = correctly_labelled_test / total_test * 100\n",
        "    test_accuracies.append(test_accuracy)\n",
        "\n",
        "    print(f\" Training accuracy = {train_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "8mXa6rxDagxV",
        "outputId": "a723f373-82e6-41d8-9946-456b1e2fcfd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/10 [14:14<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-f447483dfc1e>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0myhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mC_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-a59121aaaac2>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_jit_internal.py\u001b[0m in \u001b[0;36mfn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_max_pool2d\u001b[0;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[1;32m    794\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstride\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m         \u001b[0mstride\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 796\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mceil_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting the results"
      ],
      "metadata": {
        "id": "8OKMQEC5fPK-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting the training loss\n",
        "plt.plot(range(1, num_iter + 1), train_losses, label='Training Loss')\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss using CNN')\n",
        "plt.legend()\n",
        "\n",
        "# plotting the training and validation Accuracy\n",
        "plt.plot(range(1, num_iter + 1), train_accuracies, label='Training Accuracy')\n",
        "plt.plot(range(1, num_iter + 1), test_accuracies, label='Test Accuracy')\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training and Validation Accuracy with CNN')\n",
        "plt.legend()\n",
        "\n",
        "# Ploting the test loss\n",
        "plt.plot(range(1, num_iter + 1), test_losses, label='Test Loss')\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Test Loss with CNN')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6U5QQwSZbAdP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using a Neural Network"
      ],
      "metadata": {
        "id": "rMbOPm6Q9C68"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ia6MAyxqhiAi",
        "outputId": "27b27cb2-2c20-4050-d55c-d3ee1e071fb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [42:51<00:00, 257.10s/it]\n"
          ]
        }
      ],
      "source": [
        "#setting the initial values\n",
        "\n",
        "ni = 28*28\n",
        "nh1 = 400\n",
        "nh2 = 200\n",
        "no = 62\n",
        "\n",
        "#making the neural network\n",
        "\n",
        "class NN(nn.Module):\n",
        "  def __init__(self, ni, nh1,nh2, no):\n",
        "    super(NN,self).__init__()\n",
        "    self.l1 = nn.Linear(ni, nh1)\n",
        "    self.l2 = nn.Linear(nh1, nh2)\n",
        "    self.l3 = nn.Linear(nh2, no)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.view(-1, ni)\n",
        "    x = F.relu(self.l1(x))\n",
        "    x = F.relu(self.l2(x))\n",
        "    x = self.l3(x)\n",
        "    return x\n",
        "\n",
        "net = NN(ni, nh1,nh2, no) # defining an instance of the network\n",
        "\n",
        "# processing through gpu\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "net.to(device)\n",
        "\n",
        "#training the neural network on the train data\n",
        "\n",
        "num_iter = 10\n",
        "\n",
        "opt = optim.SGD(net.parameters(), lr = 0.01, momentum = 0.5 ) # stochastic gradient decent applied\n",
        "\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "val_accuracies = []\n",
        "total_train = 0\n",
        "correctly_labelled = 0\n",
        "for i in tqdm(range(num_iter)):\n",
        "  running_loss = 0.0\n",
        "  for x, y in train_loader:\n",
        "\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "\n",
        "    yhat = net(x) # forward pass\n",
        "\n",
        "    loss = F.cross_entropy(yhat, y) # loss\n",
        "\n",
        "    opt.zero_grad() #optimisation\n",
        "    loss.backward() # back pass\n",
        "\n",
        "    opt.step() # opt step\n",
        "\n",
        "    running_loss += loss.item()\n",
        "\n",
        " #defining the loss at each iteration and appending it to the train_losses list\n",
        "  iter_loss = running_loss/len(train_loader)\n",
        "  train_losses.append(iter_loss)\n",
        "\n",
        "# same principle for the accuracy of the data\n",
        "  total_train += x.shape[0]\n",
        "  yhat = torch.argmax(yhat, dim=1)\n",
        "  correctly_labelled = (yhat == y).sum().item()\n",
        "  train_accuracy = correctly_labelled/total_train*100\n",
        "\n",
        "  train_accuracies.append(train_accuracy)\n",
        "\n",
        "# testing the model formed above\n",
        "  net.eval()\n",
        "  correctly_labelled = 0\n",
        "  test_loss = 0\n",
        "  test_losses = []\n",
        "  error=0\n",
        "  total = 0\n",
        "  test_accuracies = []\n",
        "  with torch.no_grad():\n",
        "    epoch_acc =0\n",
        "    for x,y in test_loader:\n",
        "      x = x.to(device)\n",
        "      y = y.to(device)\n",
        "      total += x.shape[0]\n",
        "      logits = net(x)\n",
        "      yhat = torch.argmax(logits, dim=1)\n",
        "      correctly_labelled += (yhat == y).sum().item()\n",
        "      test_accuracy = correctly_labelled/total*100\n",
        "      epoch_acc += test_accuracy\n",
        "      loss = F.cross_entropy(logits, y)\n",
        "      test_loss += loss.item()\n",
        "\n",
        "      # again finding the losses and accuracies by appending to lists\n",
        "\n",
        "    test_loss = test_loss/len(test_loader)\n",
        "    test_losses.append(test_loss)\n",
        "    test_accuracies.append(epoch_acc/len(test_loader))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Test accuracy = \", test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2GJCQ01RctX",
        "outputId": "e7d1dce4-51ea-417f-d188-faab6cd70b21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy =  84.54046061398004\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing the neural network against the test data"
      ],
      "metadata": {
        "id": "4cxmkAay-TIe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UuvrkwvTr23v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "4bc22e5e-f46d-4215-eca9-8ef67d7b2e0b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'plt' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-8300935a27ac>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Plot Training Loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Training Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Iterations'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training Loss with CNN'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ],
      "source": [
        "# Plot Training Loss\n",
        "plt.plot(train_losses, label='Training Loss')\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss with CNN')\n",
        "print(train_accuracies)\n",
        "# Plot Training and Validation Accuracy\n",
        "plt.plot( train_accuracies, label='Training Accuracy')\n",
        "plt.plot(test_accuracies, label='Test Accuracy')\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training and Validation Accuracy with CNN')\n",
        "plt.legend()\n",
        "\n",
        "# Plot Test Loss\n",
        "plt.plot(test_losses, label='Test Loss')\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Test Loss with CNN')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
